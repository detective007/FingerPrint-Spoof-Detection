{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"gpuType":"T4","authorship_tag":"ABX9TyMhxeajiBYjR60ITJRwWRuK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":[" **Importing necessary libraries**"],"metadata":{"id":"rq_WSYV9VDV0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fm8Lr__7Pk7t"},"outputs":[],"source":["import pandas as pd\n","import os\n","from skimage.transform import resize\n","from skimage.io import imread\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import cv2\n","# open source implementation of LBP\n","from skimage.feature import local_binary_pattern\n","# data preprocessing and metrics module in scikit-learn\n","from sklearn import preprocessing, metrics\n","# SVM implementation in scikit-learn\n","from sklearn.svm import LinearSVC\n","import os\n","import zipfile\n","import urllib.request\n","import numpy as np\n","from PIL import Image, ImageOps\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","from matplotlib import cm\n","import seaborn as sns\n","from sklearn.svm import LinearSVC\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import argparse\n","import cv2\n","import os\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import numpy as np\n","import glob\n","import random\n","import imageio\n","import PIL, cv2\n","import pandas as pd\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from skimage.morphology import convex_hull_image, erosion\n","from skimage.morphology import square\n","import matplotlib.image as mpimg\n","import skimage\n","import math\n","from scipy.ndimage import convolve\n","from PIL import Image,ImageFilter\n","from skimage.feature import hessian_matrix, hessian_matrix_eigvals\n","from tqdm import tqdm\n","#from LBP_helper import LocalBinaryPatterns\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.svm import SVC\n","from imutils import paths"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"hIQ_HUgkV4iD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from skimage import feature\n","import numpy as np"],"metadata":{"id":"79wEC--UUBsr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_set_fake = os.listdir('/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake')\n","training_set_live = os.listdir('/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Live')\n","testing_set_fake = os.listdir('/content/drive/My Drive/Jupyter notebook/major_project/dataset/testing/Fake')\n","testing_set_live = os.listdir('/content/drive/My Drive/Jupyter notebook/major_project/dataset/testing/Live')\n","\n","paths=[]\n","for i in training_set_fake:\n","    temp = \"/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/\" + str(i)\n","    paths.append(temp)\n","for i in training_set_live:\n","    temp = \"/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Live/\" + str(i)\n","    paths.append(temp)"],"metadata":{"id":"INkg5g6_WTEp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["images = []\n","for i in paths:\n","    images.append(cv2.imread(i,0))"],"metadata":{"id":"9xV5VPZLXiX3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Data Visualization**"],"metadata":{"id":"aRpaWHw9cIOt"}},{"cell_type":"code","source":["def plot_images(*images):\n","    images = list(images)\n","    n = len(images)\n","    fig, ax = plt.subplots(ncols=n, sharey=True, figsize = (12,12))\n","    for i, img in enumerate(images):\n","        ax[i].imshow(img, cmap='gray')\n","        ax[i].axis('off')\n","    plt.subplots_adjust(left=0.03, bottom=0.03, right=0.97, top=0.97)\n","    plt.show()\n","\n","plot_images(images[0],images[1],images[2],images[3],images[4],images[5],images[6],images[7],images[8],images[9])\n","plot_images(images[10],images[11],images[12],images[13],images[14],images[15],images[16],images[17],images[18],images[19])\n","plot_images(images[20],images[21],images[22],images[23],images[24],images[25],images[26],images[27],images[28],images[29])\n","plot_images(images[30],images[31],images[32],images[33],images[34],images[35],images[36],images[37],images[38],images[39])\n","plot_images(images[40],images[41],images[42],images[43],images[44],images[45],images[46],images[47],images[48],images[49])\n","plot_images(images[50],images[51],images[52],images[53],images[54],images[55],images[56],images[57],images[58],images[59])\n","plot_images(images[60],images[61],images[62],images[63],images[64],images[65],images[66],images[67],images[68],images[69])\n","plot_images(images[70],images[71],images[72],images[73],images[74],images[75],images[76],images[77],images[78],images[79])"],"metadata":{"id":"D81jTSIIWhbh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Image enhancement and preprocessing techniques such as smoothing, thresholding and edge detection are used to make features more prominent in data for extraction to be more accurate**"],"metadata":{"id":"YEsuZPWOctxc"}},{"cell_type":"code","source":["image1 = cv2.imread('/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/27_8.png',cv2.IMREAD_GRAYSCALE)\n","image2 = cv2.imread('/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/10_8.png',cv2.IMREAD_GRAYSCALE)\n","image3 = cv2.imread('/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/122_10.png',cv2.IMREAD_GRAYSCALE)\n","\n","gauss_blur = cv2.GaussianBlur(image1,(1,1),0)\n","median_blur = cv2.medianBlur(image1,1)\n","\n","fig, axes = plt.subplots(1,3,figsize = (16,16));\n","axes[0].set_title(\"original Image\");\n","axes[0].imshow(image1);\n","axes[1].set_title(\"Gaussian Blurred Image\");\n","axes[1].imshow(gauss_blur);\n","axes[2].set_title(\"Median Blurred Image\");\n","axes[2].imshow(median_blur);"],"metadata":{"id":"mv4FsuZDcxzN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Histograms**"],"metadata":{"id":"vBvtNSrkdEoT"}},{"cell_type":"code","source":["fig, axes = plt.subplots(1,3,figsize = (18,5))\n","axes[0].hist(image1.ravel(), bins=256, color =\"r\");\n","axes[1].hist(image2.ravel(), bins=256, color =\"b\");\n","axes[2].hist(image3.ravel(), bins=256, color =\"g\");"],"metadata":{"id":"cSbvnc6qdId3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Data seems to be almost binary - implementing mean and adaptive thresholding**"],"metadata":{"id":"JdgzMxHkdSiA"}},{"cell_type":"code","source":["THRESHOLD1 = image1.mean()\n","THRESHOLD2 = image2.mean()\n","THRESHOLD3 = image3.mean()\n","\n","image1 = np.array(image1 > THRESHOLD1).astype(int) * 255\n","image2 = np.array(image2 > THRESHOLD2).astype(int) * 254\n","image3 = np.array(image3 > THRESHOLD3).astype(int) * 254\n","\n","fig, axes = plt.subplots(1,3,figsize = (16,16));\n","axes[0].imshow(image1);\n","axes[1].imshow(image2);\n","axes[2].imshow(image3);"],"metadata":{"id":"D5_MUD6VdZGa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adaptive thresholding from OpenCV library - better than Mean Thresholding\n","img1 = cv2.imread('/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/27_8.png',cv2.IMREAD_GRAYSCALE)\n","img2 = cv2.imread('/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/10_8.png',cv2.IMREAD_GRAYSCALE)\n","img3 = cv2.imread('/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/122_10.png',cv2.IMREAD_GRAYSCALE)\n","\n","\n","\n","# Otsu's thresholding\n","ret1,th1 = cv2.threshold(img1,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","ret2,th2 = cv2.threshold(img2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","ret3,th3 = cv2.threshold(img3,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","\n","fig, axes = plt.subplots(1,3,figsize = (12,12));\n","axes[0].set_title(\"Otsu's thresholding - Image 1\");\n","axes[0].imshow(th1);\n","axes[1].set_title(\"Otsu's thresholding - Image 2\");\n","axes[1].imshow(th2);\n","axes[2].set_title(\"Otsu's thresholding - Image 3\");\n","axes[2].imshow(th3);"],"metadata":{"id":"0Q0hS_BldyBA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","**Robert, Sobel, Prewitt Filters**\n"],"metadata":{"id":"oMFCcrPCeDaB"}},{"cell_type":"code","source":["vertical_robert_filter = np.array([[1,0],[0,-1]])\n","horizontal_robert_filter = np.array([[0,1],[-1,0]])\n","\n","vertical_sobel_filter = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])\n","horizontal_sobel_filter = np.array([[-1,-2,-1],[0,0,0],[1,2,1]])\n","\n","vertical_prewitt_filter = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n","horizontal_prewitt_filter = np.array([[-1,-1,-1],[0,0,0],[1,1,1]])\n","\n","print(\"vertical robert filter\\n\",vertical_robert_filter )\n","print(\"horizontal robert filter\\n\",horizontal_robert_filter)\n","print(\"vertical sobel filter: \\n\", vertical_sobel_filter)\n","print(\"horizontal sobel filter: \\n\", horizontal_sobel_filter)\n","\n","print(\"vertical prewitt filter: \\n\", vertical_prewitt_filter)\n","print(\"horizontal prewitt filter: \\n\", horizontal_prewitt_filter)"],"metadata":{"id":"qU7LvUSReF2W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gray_img = Image.fromarray(img1)\n","\n","convolved_img1 = convolve(gray_img,vertical_robert_filter)\n","convolved_img1 = convolve(convolved_img1,horizontal_robert_filter)\n","\n","convolved_img2 = convolve(gray_img,vertical_sobel_filter)\n","convolved_img2 = convolve(convolved_img2,horizontal_sobel_filter)\n","\n","convolved_img3 =  convolve(gray_img,vertical_prewitt_filter )\n","convolved_img3 =  convolve(gray_img,horizontal_prewitt_filter )\n","fig, axes = plt.subplots(1,3,figsize = (12,12));\n","axes[0].set_title(\"Robert\");\n","axes[0].imshow(convolved_img1);\n","axes[1].set_title(\"Sobel\");\n","axes[1].imshow(convolved_img2);\n","axes[2].set_title(\"Prewitt\");\n","axes[2].imshow(convolved_img3);"],"metadata":{"id":"xsg80-WneOA4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ridge Detection**"],"metadata":{"id":"XZ6ufBfIfAO-"}},{"cell_type":"code","source":["def detect_ridges(gray, sigma= 0.1):\n","    H_elems = hessian_matrix(gray, sigma=sigma, order='rc')\n","    maxima_ridges, minima_ridges = hessian_matrix_eigvals(H_elems)\n","    return maxima_ridges, minima_ridges\n","\n","def plot_images(*images):\n","    images = list(images)\n","    n = len(images)\n","    fig, ax = plt.subplots(ncols=n, sharey=True, figsize = (12,12))\n","    for i, img in enumerate(images):\n","        ax[i].imshow(img, cmap='gray')\n","        ax[i].axis('off')\n","    plt.subplots_adjust(left=0.03, bottom=0.03, right=0.97, top=0.97)\n","    plt.show()\n","\n","img = cv2.imread('/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/122_10.png', 0) # 0 imports a grayscale\n","if img is None:\n","    raise(ValueError(f\"Image didn\\'t load. Check that '{'/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/122_10.png'}' exists.\"))\n","\n","a, b = detect_ridges(img, sigma=0.15)\n","\n","plot_images(img, a, b)"],"metadata":{"id":"BYwy3-Loe8G_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**Termination and Bifurcation detection and Minutiae Extraction**\n","\n","**The given code extracts features like Termination, Bifurcation and Minutiae from finger prints, the output is shown below the code**"],"metadata":{"id":"Ze6SbcFSfRlB"}},{"cell_type":"code","source":["def getTerminationBifurcation(img, mask):\n","    img = img == 255;\n","    (rows, cols) = img.shape;\n","    minutiaeTerm = np.zeros(img.shape);\n","    minutiaeBif = np.zeros(img.shape);\n","    \n","    for i in range(1,rows-1):\n","        for j in range(1,cols-1):\n","            if(img[i][j] == 1):\n","                block = img[i-1:i+2,j-1:j+2];\n","                block_val = np.sum(block);\n","                if(block_val == 2):\n","                    minutiaeTerm[i,j] = 1;\n","                elif(block_val == 4):\n","                    minutiaeBif[i,j] = 1;\n","    \n","    mask = convex_hull_image(mask>0)\n","    mask = erosion(mask, square(5))         \n","    minutiaeTerm = np.uint8(mask)*minutiaeTerm\n","    return(minutiaeTerm, minutiaeBif)"],"metadata":{"id":"TTs0lIpafLPP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MinutiaeFeature(object):\n","    def __init__(self, locX, locY, Orientation, Type):\n","        self.locX = locX;\n","        self.locY = locY;\n","        self.Orientation = Orientation;\n","        self.Type = Type;\n","\n","def computeAngle(block, minutiaeType):\n","    angle = 0\n","    (blkRows, blkCols) = np.shape(block);\n","    CenterX, CenterY = (blkRows-1)/2, (blkCols-1)/2\n","    if(minutiaeType.lower() == 'termination'):\n","        sumVal = 0;\n","        for i in range(blkRows):\n","            for j in range(blkCols):\n","                if((i == 0 or i == blkRows-1 or j == 0 or j == blkCols-1) and block[i][j] != 0):\n","                    angle = -math.degrees(math.atan2(i-CenterY, j-CenterX))\n","                    sumVal += 1\n","                    if(sumVal > 1):\n","                        angle = float('nan');\n","        return(angle)\n","    elif(minutiaeType.lower() == 'bifurcation'):\n","        (blkRows, blkCols) = np.shape(block);\n","        CenterX, CenterY = (blkRows - 1) / 2, (blkCols - 1) / 2\n","        angle = []\n","        sumVal = 0;\n","        for i in range(blkRows):\n","            for j in range(blkCols):\n","                if ((i == 0 or i == blkRows - 1 or j == 0 or j == blkCols - 1) and block[i][j] != 0):\n","                    angle.append(-math.degrees(math.atan2(i - CenterY, j - CenterX)))\n","                    sumVal += 1\n","        if(sumVal != 3):\n","            angle = float('nan')\n","        return(angle)\n","\n","\n","def extractMinutiaeFeatures(skel, minutiaeTerm, minutiaeBif):\n","    FeaturesTerm = []\n","\n","    minutiaeTerm = skimage.measure.label(minutiaeTerm, connectivity=2);\n","    RP = skimage.measure.regionprops(minutiaeTerm)\n","    \n","    WindowSize = 2          \n","    FeaturesTerm = []\n","    for i in RP:\n","        (row, col) = np.int16(np.round(i['Centroid']))\n","        block = skel[row-WindowSize:row+WindowSize+1, col-WindowSize:col+WindowSize+1]\n","        angle = computeAngle(block, 'Termination')\n","        FeaturesTerm.append(MinutiaeFeature(row, col, angle, 'Termination'))\n","\n","    FeaturesBif = []\n","    minutiaeBif = skimage.measure.label(minutiaeBif, connectivity=2);\n","    RP = skimage.measure.regionprops(minutiaeBif)\n","    WindowSize = 1 \n","    for i in RP:\n","        (row, col) = np.int16(np.round(i['Centroid']))\n","        block = skel[row-WindowSize:row+WindowSize+1, col-WindowSize:col+WindowSize+1]\n","        angle = computeAngle(block, 'Bifurcation')\n","        FeaturesBif.append(MinutiaeFeature(row, col, angle, 'Bifurcation'))\n","    return(FeaturesTerm, FeaturesBif)\n","\n","def ShowResults(skel, TermLabel, BifLabel):\n","    minutiaeBif = TermLabel * 0;\n","    minutiaeTerm = BifLabel * 0;\n","\n","    (rows, cols) = skel.shape\n","    DispImg = np.zeros((rows, cols, 3), np.uint8)\n","    DispImg[:, :, 0] = skel;\n","    DispImg[:, :, 1] = skel;\n","    DispImg[:, :, 2] = skel;\n","\n","    RP = skimage.measure.regionprops(BifLabel)\n","    for idx, i in enumerate(RP):\n","        (row, col) = np.int16(np.round(i['Centroid']))\n","        minutiaeBif[row, col] = 1;\n","        (rr, cc) = skimage.draw.circle_perimeter(row, col, 1);\n","        skimage.draw.set_color(DispImg, (rr, cc), (255, 0, 0));\n","\n","    RP = skimage.measure.regionprops(TermLabel)\n","    for idx, i in enumerate(RP):\n","        (row, col) = np.int16(np.round(i['Centroid']))\n","        minutiaeTerm[row, col] = 1;\n","        (rr, cc) = skimage.draw.circle_perimeter(row, col, 1);\n","        skimage.draw.set_color(DispImg, (rr, cc), (0, 0, 255));\n","        \n","    plt.figure(figsize=(6,6))\n","    plt.title(\"Minutiae extraction results\")\n","    plt.imshow(DispImg)"],"metadata":{"id":"zQm2u7_Jfvyx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = cv2.imread('/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Live/9_2.png',0)\n","# img = cv2.imread(img_name,0);\n","img = np.array(img > THRESHOLD1).astype(int)\n","skel = skimage.morphology.skeletonize(img)\n","skel = np.uint8(skel)*255;\n","mask = img*255;\n","\n","(minutiaeTerm, minutiaeBif) = getTerminationBifurcation(skel, mask);\n","FeaturesTerm, FeaturesBif = extractMinutiaeFeatures(skel, minutiaeTerm, minutiaeBif)\n","BifLabel = skimage.measure.label(minutiaeBif, connectivity=1);\n","TermLabel = skimage.measure.label(minutiaeTerm, connectivity=1);\n","ShowResults(skel, TermLabel, BifLabel)"],"metadata":{"id":"UG-7ASsrfzfa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["paths_all=[]\n","X =[]\n","features_all=[]\n","for i in training_set_fake:\n","    temp = \"/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/\" + str(i)\n","    paths_all.append(temp)\n","for i in training_set_live:\n","    temp = \"/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Live/\" + str(i)\n","    paths_all.append(temp)\n","\n","for i in testing_set_fake:\n","    temp = \"/content/drive/My Drive/Jupyter notebook/major_project/dataset/testing/Fake/\" + str(i)\n","    paths_all.append(temp)\n","for i in testing_set_live:\n","    temp = \"/content/drive/My Drive/Jupyter notebook/major_project/dataset/testing/Live/\" + str(i)\n","    paths_all.append(temp)\n","\n","labels_all=[]\n","for imagePath in paths_all:\n","    img =  cv2.imread(imagePath,0)\n","    img = np.array(img > THRESHOLD1).astype(int)\n","    skel = skimage.morphology.skeletonize(img)\n","    skel = np.uint8(skel)*255;\n","    mask = img*255;\n","\n","    (minutiaeTerm, minutiaeBif) = getTerminationBifurcation(skel, mask);\n","    FeaturesTerm, FeaturesBif = extractMinutiaeFeatures(skel, minutiaeTerm, minutiaeBif)\n","    labels_all.append(imagePath.split(os.path.sep)[-2])\n","    features_all.append([FeaturesTerm, FeaturesBif])"],"metadata":{"id":"IU-5_6N9Zu_l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extracting LBP features From the Image dataset**"],"metadata":{"id":"Fuxv6UnGthvc"}},{"cell_type":"code","source":["from skimage import feature\n","import numpy as np\n","\n","class LocalBinaryPatterns:\n","    def __init__(self, numPoints, radius):\n","        \n","    # store the number of points and radius\n","        self.numPoints = numPoints\n","        self.radius = radius\n","        \n","    def describe(self, image, eps=1e-7):\n","        \n","        # compute the Local Binary Pattern representation\n","        # of the image, and then use the LBP representation\n","        # to build the histogram of patterns\n","        \n","        lbp = feature.local_binary_pattern(image, self.numPoints, self.radius, method=\"uniform\")\n","        (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, self.numPoints + 3), range=(0, self.numPoints + 2))\n","        \n","        # normalize the histogram\n","        hist = hist.astype(\"float\")\n","        hist /= (hist.sum() + eps)\n","        \n","        # return the histogram of Local Binary Patterns\n","        return hist"],"metadata":{"id":"o3OLCV9Syd5V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["desc = LocalBinaryPatterns(24, 8)\n","training_data = []\n","training_labels = []\n","\n","testing_data = []\n","testing_labels = []\n","\n","pridicted_label_set=[]"],"metadata":{"id":"pO8izTMXT-Up"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["paths_all=[]\n","data_all=[]\n","for i in training_set_fake:\n","    temp = \"/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Fake/\" + str(i)\n","    paths_all.append(temp)\n","for i in training_set_live:\n","    temp = \"/content/drive/My Drive/Jupyter notebook/major_project/dataset/training/Live/\" + str(i)\n","    paths_all.append(temp)\n","\n","for i in testing_set_fake:\n","    temp = \"/content/drive/My Drive/Jupyter notebook/major_project/dataset/testing/Fake/\" + str(i)\n","    paths_all.append(temp)\n","for i in testing_set_live:\n","    temp = \"/content/drive/My Drive/Jupyter notebook/major_project/dataset/testing/Live/\" + str(i)\n","    paths_all.append(temp)\n","\n","labels_all=[]\n","for imagePath in paths_all:\n","    # load the image, convert it to grayscale, and describe it\n","    image = cv2.imread(imagePath)\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    hist = desc.describe(gray)\n","    # extract the label from the image path, then update the\n","    # label and data lists\n","    labels_all.append(imagePath.split(os.path.sep)[-2])\n","    data_all.append(hist)"],"metadata":{"id":"CcmTCQPxtame"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(data_all, labels_all, test_size=0.2, shuffle=True)"],"metadata":{"id":"R-_Nj6MEt5L2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Applying  SVM model**"],"metadata":{"id":"PUC_TexxuAZ2"}},{"cell_type":"code","source":["grid_search = GridSearchCV(SVC(kernel='rbf'),\n","                           param_grid={'C': [10, 100, 1000, 10000, 100000], 'gamma': [100, 10, 1, 0.1, 0.01, .0001]},\n","                           cv=5, verbose=True)\n","grid_search.fit(x_train, y_train)\n","params = grid_search.best_params_\n","print(\"Best parameter: \", params)\n","\n","model = SVC(kernel='rbf', C=params['C'], gamma=params['gamma'], probability=True,verbose=True)\n","model.fit(x_train, y_train)"],"metadata":{"id":"4oE0ejnFt-qO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.score(x_test, y_test)\n","print(model.predict(x_test[1].reshape(1, -1)))\n","print(model.predict_proba(x_test[1].reshape(1, -1)))\n","print(\"Test accuracy: \", model.score(x_test, y_test))\n","print(\"train accuracy: \", model.score(x_train, y_train))"],"metadata":{"id":"czGvSGqJuVUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","y_pred = model.predict(x_test)\n","print(confusion_matrix(y_test, y_pred))\n","print(model.classes_)"],"metadata":{"id":"2szxES1e16jv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Applying KNN binary classification**"],"metadata":{"id":"2fq6C2qdul9x"}},{"cell_type":"code","source":["#Applying KNN binary classification\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)"],"metadata":{"id":"EXceGHyCukYq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier(n_neighbors=3)\n","knn.fit(x_train, y_train)"],"metadata":{"id":"jiwBd-HTuwsO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = knn.predict(x_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"id":"hr7yPeC2u0hX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Applying NaiveBayes**\n"],"metadata":{"id":"g1ioy5DwxBSE"}},{"cell_type":"code","source":["#using naive bayes\n","from sklearn.naive_bayes import GaussianNB\n","model = GaussianNB()\n","model.fit(x_train, y_train)\n","y_pred = model.predict(x_test)\n","accuracy = accuracy_score(y_test,y_pred)\n","print(\"Accuracy:\", accuracy)\n","print(confusion_matrix(y_test, y_pred))\n","print(model.classes_)"],"metadata":{"id":"NzJjhsAsxHkN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Appliying Decision Tree**"],"metadata":{"id":"O19hHJqSxQP3"}},{"cell_type":"code","source":["#decision tree\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","\n","\n","model = DecisionTreeClassifier()\n","\n","# Train the model\n","model.fit(x_train, y_train)\n","\n","# Evaluate the model\n","y_pred = model.predict(x_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","print(confusion_matrix(y_test, y_pred))"],"metadata":{"id":"idmLTxFyxTau"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Applying LogisticRegression model**"],"metadata":{"id":"gOzM4m9uxgL_"}},{"cell_type":"code","source":["#logistic regression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","\n","# Create the logistic regression classifier model\n","model = LogisticRegression(solver='liblinear', random_state=0)\n","\n","# Train the model\n","model.fit(x_train, y_train)\n","\n","# Evaluate the model\n","y_pred = model.predict(x_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","print(confusion_matrix(y_test, y_pred))\n","\n"],"metadata":{"id":"2qYgeu2Mxkpb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Applying CNN deep learning model**"],"metadata":{"id":"2Nz9rV8Wu56G"}},{"cell_type":"code","source":["import os\n","\n","import joblib\n","\n","train_path = '/content/drive/My Drive/Jupyter notebook/major_project/dataset/training'\n","test_path = '/content/drive/My Drive/Jupyter notebook/major_project/dataset/testing'\n","\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","train_data = ImageDataGenerator(rescale=1. / 255)\n","train_set = train_data.flow_from_directory(directory=train_path, target_size=(128, 128), batch_size=32,\n","                                           color_mode=\"rgb\", class_mode='binary')\n","\n","test_data = ImageDataGenerator(rescale=1. / 255)\n","test_set = train_data.flow_from_directory(directory=test_path, target_size=(128, 128), batch_size=32, color_mode=\"rgb\",\n","                                          class_mode='binary')"],"metadata":{"id":"vUzRl59yu9ka"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n","\n","model = Sequential()\n","\n","# first layer\n","model.add(Conv2D(32, (3, 3), input_shape=(128, 128, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# second layer\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# flattern layer\n","model.add(Flatten())\n","\n","# Dense layer\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model_history = model.fit(train_set, validation_data=test_set, epochs=10)"],"metadata":{"id":"nfu4SwutvFxj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","\n","plt.plot(np.arange(0, 10), model_history.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, 10), model_history.history[\"val_accuracy\"], label=\"val_accuracy\")\n","\n","plt.title(\"Training and validation Accuracy on Dataset\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"lower left\")\n","model.save(os.path.join(\"./model/\", \"CNN_classification.h5\"))"],"metadata":{"id":"1RZ_4n6lvLP7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Checking Image**"],"metadata":{"id":"DpTuqNZgvPri"}},{"cell_type":"code","source":["# check image\n","import numpy as np\n","from tensorflow.keras.preprocessing import image\n","import tensorflow as tf\n","\n","model = tf.keras.models.load_model('/content/model/CNN_classification.h5')\n","test_image = image.load_img('/content/drive/My Drive/Jupyter notebook/major_project/dataset/testing/Live/9_2.png', target_size=(128, 128))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis=0)\n","result = model.predict(test_image)\n","# train_set.class_indices\n","if result[0][0] == 1:\n","    prediction = 'Live'\n","else:\n","    prediction = 'Fake'\n","print(prediction)"],"metadata":{"id":"3x92qe-uvS9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_weights(\"/content/model/CNN_classification.h5\")\n","test_image = image.load_img('/content/drive/My Drive/Jupyter notebook/major_project/mythumb.jpeg', target_size=(128, 128))\n","test_image = image.img_to_array(test_image)\n","prediction = model.predict(np.expand_dims(test_image, axis=0))[0]\n","scores = [1 - prediction[0], prediction[0]]\n","\n","class_names = [\"Fake\", \"Live\"]\n","for score, name in zip(scores, class_names):\n","    print(\n","        \"This model is %.2f percent confident that fingerprint is %s\"\n","        % ((100 * score), name)\n","    )"],"metadata":{"id":"cNvT9ASvvYBn"},"execution_count":null,"outputs":[]}]}